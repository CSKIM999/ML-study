{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-522b4029de7c>:19: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n  sheet = wb.get_sheet_by_name('ML result')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np \n",
    "import openpyxl as xl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "sns.set()\n",
    "try:\n",
    "    wb=xl.load_workbook('testing.xlsx')\n",
    "    sheet = wb.get_sheet_by_name('ML result')\n",
    "except FileNotFoundError:\n",
    "    wb = xl.Workbook()\n",
    "    sheet = wb.active\n",
    "    sheet.title='ML result'\n",
    "    \n",
    "\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "\n",
    "train_test_data  = [train,test]\n",
    "\n",
    "for dataset in  train_test_data:\n",
    "    dataset['Title']=dataset['Name'].str.extract('([A-Za-z]+)\\.',expand=False)\n"
   ]
  },
  {
   "source": [
    "# TITLE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset  in train_test_data:\n",
    "#     dataset['Title'] = dataset['Title'].replace(['Lady','Capt','Col','Countess','Don','Dona','Dr','Jonkheer','Major','Sir'],'Rare')\n",
    "#     dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'],'Miss')\n",
    "#     dataset['Title'] = dataset['Title'].replace('Mme','Mrs')\n",
    "\n",
    "# title_mapping = {'Mr':0,'Master':0.4,'Rev':0.8,'Miss':1.2,'Mrs':1.6,'Rare':2}\n",
    "\n",
    "for dataset  in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Rev','Lady','Capt','Master','Col','Countess','Don','Dona','Dr','Jonkheer','Major','Sir'],'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'],'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme','Mrs')\n",
    "\n",
    "title_mapping = {'Mr':0,'Miss':1,'Mrs':2,'Rare':3}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Survived    0    1\n",
       "Title             \n",
       "0         436   81\n",
       "1          55  130\n",
       "2          26  100\n",
       "3          32   31"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Survived</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>Title</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>436</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32</td>\n      <td>31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "pd.crosstab(train['Title'],train['Survived'])"
   ]
  },
  {
   "source": [
    "# SEX"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Name',axis=1,inplace=True)\n",
    "test.drop('Name',axis=1,inplace=True)\n",
    "for dataset  in train_test_data:\n",
    "    dataset['Sex'] = dataset['Sex'].replace('male',0)\n",
    "    dataset['Sex'] = dataset['Sex'].replace('female',1)"
   ]
  },
  {
   "source": [
    "# AGE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].fillna(train.groupby('Title')['Age'].transform('median'),inplace=True)\n",
    "test['Age'].fillna(test.groupby('Title')['Age'].transform('median'),inplace=True)\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Age'] <= 18, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 35), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 45), 'Age'] = 2\n",
    "    dataset.loc[ dataset['Age'] > 45, 'Age'] = 3\n"
   ]
  },
  {
   "source": [
    "# EMBARKED"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset[\"Embarked\"]=dataset['Embarked'].fillna('S')\n",
    "\n",
    "embarked_mapping = {'S':0,'C':1,'Q':2}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Embarked']=dataset['Embarked'].map(embarked_mapping)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "source": [
    "# FARE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'].fillna(train.groupby('Pclass')['Fare'].transform('median'),inplace=True)\n",
    "test['Fare'].fillna(test.groupby('Pclass')['Fare'].transform('median'),inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Fare'] <= 15, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 15) & (dataset['Fare'] <= 35), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 35) & (dataset['Fare'] <= 100), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3\n",
    "\n",
    "#     # dataset.loc[ dataset['Fare'] <= 10, 'Fare'] = 0\n",
    "#     # dataset.loc[(dataset['Fare'] > 10) & (dataset['Fare'] <= 20), 'Fare'] = 1\n",
    "#     # dataset.loc[(dataset['Fare'] > 20) & (dataset['Fare'] <= 30), 'Fare'] = 2\n",
    "#     # dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 50), 'Fare'] = 3\n",
    "#     # dataset.loc[(dataset['Fare'] > 50) & (dataset['Fare'] <= 100), 'Fare'] = 4\n",
    "#     # dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 5\n",
    "\n",
    "    dataset['Fare'] = dataset['Fare'].round(0)\n"
   ]
  },
  {
   "source": [
    "# CABIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] =dataset['Cabin'].str[:1]\n",
    "    \n",
    "# cabin_mapping = {'A':0,'B':0.4,'C':0.8,'D':1.2,'E':1.6,'F':2,'G':2.4,'T':2.8}\n",
    "cabin_mapping = {'A':0,'B':0.4,'C':0.8,'D':1.2,'E':1.2,'F':1.6,'G':2,'T':2}\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Cabin']=dataset['Cabin'].map(cabin_mapping)\n",
    "\n",
    "train['Cabin'].fillna(train.groupby('Pclass')['Cabin'].transform('median'),inplace=True)\n",
    "test['Cabin'].fillna(test.groupby('Pclass')['Cabin'].transform('median'),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Survived    0    1\n",
       "Cabin             \n",
       "0.0         8    7\n",
       "0.4        12   35\n",
       "0.8        45   54\n",
       "1.2        16   49\n",
       "1.4        94   74\n",
       "1.6       371  121\n",
       "2.0         3    2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Survived</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>Cabin</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>0.4</th>\n      <td>12</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>0.8</th>\n      <td>45</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>1.2</th>\n      <td>16</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>1.4</th>\n      <td>94</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>1.6</th>\n      <td>371</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pd.crosstab(train['Cabin'],train['Survived'])"
   ]
  },
  {
   "source": [
    "# FAM-SIZE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['FamilySize'] = train['SibSp']+train['Parch'] + 1\n",
    "test['FamilySize'] = test['SibSp']+test['Parch'] + 1\n",
    "# family_mapping={1:0, 2:0.2, 3:0.4, 4:0.6, 5:0.8, 6:1, 7:1.2, 8:1.4,8:1.6, 9:1.8, 11:2}\n",
    "family_mapping={1:0, 2:0.2, 3:0.4, 4:0.6, 5:0.6, 6:0.8, 7:0.8, 8:0.8,11:0.8}\n",
    "for dataset in train_test_data:\n",
    "    dataset['FamilySize']=dataset['FamilySize'].map(family_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Survived      0    1\n",
       "FamilySize          \n",
       "0.0         374  163\n",
       "0.2          72   89\n",
       "0.4          43   59\n",
       "0.6          20   24\n",
       "0.8          40    7"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Survived</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>FamilySize</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>374</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>0.2</th>\n      <td>72</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>0.4</th>\n      <td>43</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>0.6</th>\n      <td>20</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>0.8</th>\n      <td>40</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "pd.crosstab(train['FamilySize'],train['Survived'])\n",
    "# train['FamilySize'].value_counts().sort_index()"
   ]
  },
  {
   "source": [
    "## ===================================================="
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_drop = ['Ticket','SibSp','Parch']\n",
    "train=train.drop(feature_drop,axis=1)\n",
    "test=test.drop(feature_drop,axis=1)\n",
    "train=train.drop(['PassengerId'],axis=1)\n",
    "\n",
    "train_data = train.drop('Survived',axis=1)\n",
    "target = train['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.81111111 0.78651685 0.79775281 0.80898876 0.85393258 0.82022472\n 0.83146067 0.7752809  0.82022472 0.82022472]\n============================\nkNN Result : 81.26\n============================\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data,target,cv = k_fold,n_jobs=1,scoring=scoring)\n",
    "kNN_Result = round(np.mean(score)*100,2)\n",
    "print(score)\n",
    "print('============================')\n",
    "print('kNN Result : ' + str(kNN_Result))\n",
    "print('============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.77777778 0.85393258 0.76404494 0.80898876 0.83146067 0.85393258\n 0.83146067 0.80898876 0.74157303 0.7752809 ]\n============================\nDecisionTree Result : 80.47\n============================\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "DecisionTree_Result = round(np.mean(score)*100,2)\n",
    "print(score)\n",
    "print('============================')\n",
    "print('DecisionTree Result : ' + str(DecisionTree_Result))\n",
    "print('============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.82222222 0.86516854 0.74157303 0.79775281 0.83146067 0.83146067\n",
      " 0.79775281 0.78651685 0.76404494 0.82022472]\n",
      "============================\n",
      "RandomForest Result : 80.58\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "RandomForest_Result = round(np.mean(score)*100,2)\n",
    "print(score)\n",
    "print('============================')\n",
    "print('RandomForest Result : ' + str(RandomForest_Result))\n",
    "print('============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.78888889 0.71910112 0.73033708 0.71910112 0.68539326 0.80898876\n 0.70786517 0.74157303 0.80898876 0.83146067]\n============================\nGaussianNB Result : 75.42\n============================\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\r\n",
    "scoring = 'accuracy'\r\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\r\n",
    "GaussianNB_Result = round(np.mean(score)*100,2)\r\n",
    "print(score)\r\n",
    "print('============================')\r\n",
    "print('GaussianNB Result : ' + str(GaussianNB_Result))\r\n",
    "print('============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.82222222 0.78651685 0.79775281 0.80898876 0.84269663 0.83146067\n",
      " 0.82022472 0.80898876 0.80898876 0.84269663]\n",
      "============================\n",
      "SVC Result : 81.71\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "SVC_Result = round(np.mean(score)*100,2)\n",
    "print(score)\n",
    "print('============================')\n",
    "print('SVC Result : ' + str(SVC_Result))\n",
    "print('============================')"
   ]
  },
  {
   "source": [
    "## Save Result Data in Result_save_file "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=1\n",
    "# idx = 2\n",
    "# if sheet['A{}'.format(idx)].value != None:\n",
    "#     idx+=1 \n",
    "# else:\n",
    "#     index = idx\n",
    "\n",
    "# while True:\n",
    "#     if sheet['A{}'.format(index)].value == None:\n",
    "#         break\n",
    "#     index+=1\n",
    "# datas = (index-1,kNN_Result,DecisionTree_Result,RandomForest_Result,GaussianNB_Result,SVC_Result)\n",
    "# col_names = ['Index','kNN','DecisionTree','RandomForest','GaussianNB','SVM']\n",
    "\n",
    "# for seq, name in enumerate(col_names):\n",
    "#     sheet.cell(row=1, column=seq+1, value=name)\n",
    "# for seq, name in enumerate(datas):\n",
    "#     sheet.cell(row=index,column=seq+1,value=name)\n",
    "\n",
    "# print(sheet['A{}'.format(index)].value)\n",
    "\n",
    "# wb.save('testing.xlsx')"
   ]
  },
  {
   "source": [
    "# **Make result File**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC()\n",
    "# clf.fit(train_data,target)\n",
    "\n",
    "# test_data = test.drop('PassengerId',axis=1).copy()\n",
    "# prediction = clf.predict(test_data)\n",
    "# submission = pd.DataFrame({\n",
    "#     'PassengerId':test['PassengerId'],\n",
    "#     'Survived':prediction\n",
    "# })\n",
    "\n",
    "# submission.to_csv('submission_1.csv',index=False)\n",
    "\n",
    "# submission = pd.read_csv('submission_1.csv')\n",
    "# submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ^: 'float' and 'int'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-a1082a5297a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m9500\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m^\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for ^: 'float' and 'int'"
     ]
    }
   ],
   "source": []
  }
 ]
}